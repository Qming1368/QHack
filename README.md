# QHack

### Project Description: 

The goal of this project is to explore and demonstrate the advantage of hybrid quantum-classical neural network (QCNN) over classical models (e.g. convolutional neural networks) by conducting three experiments. 

The first experiment can be considered as a warm-up for building hybrid QCNNs. We create a simple hybrid model by integrating a quantum version of binary classifier to a LeNet-like CNN model. We train this model on the MNIST dataset of handwritten digits. Since this task is a binary classification problem, we only select two types of digits (0 and 1) from the MNIST dataset.

In the second experiment, we design a quantum activation function by using parametrized quantum circuits and implement it in a hybrid QCNN model. The architecture of this model is very similar with the one in the first experiment except that the quantum activation function is integrated to the network and the quantum classifier is replaced with the classical softmax classifier (so we perform multi-class classification tasks in this case). In addition, we build another two classical CNN models by simply replacing the quantum activation function in the hybrid QCNN model with the sigmoid and tanh function respectively. After that, we conduct performance analysis of these three activation functions by training their corresponding models on the MNIST dataset and checking the model performances in terms of loss and accuracy curves. We observe from the results that parameterized quantum circuits help avoid vanishing gradient problem and can be considered as a good option for activation function in deep learning models. We also prove this advantage of parameterized quantum circuits by analytic calculation in the context of quantum mechanics which will be shown in the [final presentation](https://github.com/Qming1368/QHack/tree/main/finnal%20presentation).

The last experiment is inspired by the research [demo](https://pennylane.ai/qml/demos/tutorial_quantum_transfer_learning.html) of quantum transfer learning from pennylane which implement the idea of the [literature](https://arxiv.org/abs/1912.08278). Following the idea of dressed quantum circuits in this paper, we build a hybrid model based on the pre-trained network ResNet18 and compare its performance against the classical ResNet18 model over a set of public imaging datasets. In addition to the MNIST and Hymenoptera datasets used in the original paper, we use more public datasets including medical imaging datasets. We demonstrate the quantum advantage of hybrid models and investigate where this advantage comes from. We observe that in light of quantum entanglement hybrid quantum models can obtain up to 6% increase in recognition accuracy over classical CNN models. Furthermore, after we were awarded $4000 Power Up AWS credits, we performed more experiments on both SV1 simulator and Rigetti Aspen-9 quantum computer provided by AWS Braket Service. The corresponding results have been updated in the final presentation.
